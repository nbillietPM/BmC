{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bdab56-0160-481b-af4a-948584f62c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b263cb-78e0-404c-a86f-b8e5af1a025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing files in bucket: chelsav2 with prefix: GLOBAL/monthly/\n",
      "An error occurred: Unable to locate credentials\n",
      "Double-check the BUCKET_NAME, PREFIX, and ENDPOINT_URL.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for the Specific Bucket ---\n",
    "# The bucket name is the part after the host in the path\n",
    "BUCKET_NAME = 'chelsav2'\n",
    "# The prefix is the folder path you want to list\n",
    "PREFIX = 'GLOBAL/monthly/'\n",
    "# This is the custom endpoint URL for SWITCH Cloud Object Storage\n",
    "ENDPOINT_URL = 'https://os.zhdk.cloud.switch.ch'\n",
    "# Region is often required, but you can use a placeholder for public buckets\n",
    "REGION_NAME = 'us-east-1' \n",
    "\n",
    "def list_all_files_in_s3(bucket_name, prefix, endpoint_url, region_name):\n",
    "    \"\"\"\n",
    "    Lists all object keys (file paths) in an S3-compatible bucket,\n",
    "    handling pagination automatically.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the S3 client\n",
    "    # Since this is a public bucket, we often don't need credentials,\n",
    "    # but the endpoint_url and region_name are mandatory for non-AWS S3.\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=endpoint_url,\n",
    "        region_name=region_name\n",
    "        # If the bucket were private, you'd add: \n",
    "        # aws_access_key_id='YOUR_KEY', \n",
    "        # aws_secret_access_key='YOUR_SECRET'\n",
    "    )\n",
    "    \n",
    "    # Use the Paginator to automatically handle large numbers of files\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    pages = paginator.paginate(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=prefix\n",
    "    )\n",
    "    \n",
    "    all_files = []\n",
    "    \n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            # 'Contents' is a list of dictionaries, one for each file\n",
    "            for obj in page['Contents']:\n",
    "                # The 'Key' is the full file path/name\n",
    "                all_files.append(obj['Key'])\n",
    "                \n",
    "    return all_files\n",
    "\n",
    "# --- Execute the function ---\n",
    "print(f\"Listing files in bucket: {BUCKET_NAME} with prefix: {PREFIX}\")\n",
    "try:\n",
    "    file_list = list_all_files_in_s3(BUCKET_NAME, PREFIX, ENDPOINT_URL, REGION_NAME)\n",
    "\n",
    "    if file_list:\n",
    "        print(f\"\\nSuccessfully found {len(file_list)} files.\")\n",
    "        print(\"\\n--- First 5 Files ---\")\n",
    "        for file_key in file_list[:5]:\n",
    "            print(f\"- {file_key}\")\n",
    "        print(\"---------------------\\n\")\n",
    "        \n",
    "        # Now you can use this `file_list` in your URL generator test\n",
    "        # to ensure the files exist before attempting to download them.\n",
    "\n",
    "    else:\n",
    "        print(\"No files found with the specified prefix.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Double-check the BUCKET_NAME, PREFIX, and ENDPOINT_URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011559c5-73c6-4063-8e09-bfa35fe7dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 1C25-B250\n",
      "\n",
      " Directory of C:\\Users\\niels\\Documents\\Repositories\\BmC\\tests\\datasource\\chelsa\n",
      "\n",
      "03/10/2025  11:04    <DIR>          .\n",
      "02/10/2025  15:39    <DIR>          ..\n",
      "03/10/2025  11:02    <DIR>          .ipynb_checkpoints\n",
      "02/10/2025  16:08    <DIR>          __pycache__\n",
      "02/10/2025  16:19                35 test_s3.py\n",
      "03/10/2025  11:04             4.285 Untitled.ipynb\n",
      "03/10/2025  11:05    <DIR>          urls\n",
      "               2 File(s)          4.320 bytes\n",
      "               5 Dir(s)  233.413.570.560 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe02ade-57c9-43a1-b9f0-28de7c33a634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clt.txt',\n",
       " 'cmi.txt',\n",
       " 'hurs.txt',\n",
       " 'pet.txt',\n",
       " 'pr.txt',\n",
       " 'rsds.txt',\n",
       " 'sfcWind.txt',\n",
       " 'tas.txt',\n",
       " 'tasmax.txt',\n",
       " 'tasmin.txt',\n",
       " 'vas.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"urls/monthly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600fed16-1b2a-453e-8717-9602a1d72cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clt',\n",
       " 'cmi',\n",
       " 'hurs',\n",
       " 'pet',\n",
       " 'pr',\n",
       " 'rsds',\n",
       " 'sfcWind',\n",
       " 'tas',\n",
       " 'tasmax',\n",
       " 'tasmin',\n",
       " 'vas']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_url_lists = os.listdir(\"urls/monthly\")\n",
    "[file_name.split(\".\")[0] for file_name in variable_url_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69554821-eea1-40b8-8609-caf1fcbe3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in variable_url_lists:\n",
    "    filepath = os.path.join(\"urls/monthly\", filename)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        urls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a66998-ed5c-4333-ba9d-81aea727f76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://os.zhdk.cloud.switch.ch/chelsav2/GLOBAL/monthly/vpd/CHELSA_vpd_01_1980_V.2.1.tif'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0262fae4-337f-4f6c-8a1b-989067c02f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.windows import from_bounds\n",
    "from affine import Affine\n",
    "def make_dummy_tif(path, width=100, height=80, ulx=1000.0, uly=2000.0, pixel_size=1.0):\n",
    "    \"\"\"Create a deterministic single-band GeoTIFF: values = row*width + col (i.e. np.arange)\"\"\"\n",
    "    arr = np.arange(width * height, dtype=np.int32).reshape((height, width))\n",
    "    transform = from_origin(ulx, uly, pixel_size, pixel_size)\n",
    "    profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": arr.dtype,\n",
    "        \"count\": 1,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"crs\": \"EPSG:4326\",\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "    with rasterio.open(path, \"w\", **profile) as dst:\n",
    "        dst.write(arr, 1)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a683bb-729d-40de-83b6-19475551dc27",
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "Attempt to create new tiff file '' failed: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mrasterio\\\\_io.pyx:1530\u001b[0m, in \u001b[0;36mrasterio._io.DatasetWriterBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_err.pyx:359\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: Attempt to create new tiff file '' failed: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m make_dummy_tif(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36mmake_dummy_tif\u001b[1;34m(path, width, height, ulx, uly, pixel_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m transform \u001b[38;5;241m=\u001b[39m from_origin(ulx, uly, pixel_size, pixel_size)\n\u001b[0;32m     10\u001b[0m profile \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGTiff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: arr\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m: transform,\n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprofile) \u001b[38;5;28;01mas\u001b[39;00m dst:\n\u001b[0;32m     20\u001b[0m     dst\u001b[38;5;241m.\u001b[39mwrite(arr, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\rasterio\\env.py:463\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\rasterio\\__init__.py:378\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m writer \u001b[38;5;241m=\u001b[39m get_writer_for_driver(driver)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m writer(\n\u001b[0;32m    379\u001b[0m         path,\n\u001b[0;32m    380\u001b[0m         mode,\n\u001b[0;32m    381\u001b[0m         driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    382\u001b[0m         width\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[0;32m    383\u001b[0m         height\u001b[38;5;241m=\u001b[39mheight,\n\u001b[0;32m    384\u001b[0m         count\u001b[38;5;241m=\u001b[39mcount,\n\u001b[0;32m    385\u001b[0m         crs\u001b[38;5;241m=\u001b[39mcrs,\n\u001b[0;32m    386\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m    387\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    388\u001b[0m         nodata\u001b[38;5;241m=\u001b[39mnodata,\n\u001b[0;32m    389\u001b[0m         sharing\u001b[38;5;241m=\u001b[39msharing,\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    391\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverCapabilityError(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriter does not exist for driver: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(driver)\n\u001b[0;32m    395\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:1542\u001b[0m, in \u001b[0;36mrasterio._io.DatasetWriterBase.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRasterioIOError\u001b[0m: Attempt to create new tiff file '' failed: No such file or directory"
     ]
    }
   ],
   "source": [
    "test = make_dummy_tif(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b392315-0410-4333-8a98-2945348d1995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
